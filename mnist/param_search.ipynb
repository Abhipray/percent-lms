{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from nn import *\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "np.random.seed(100)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the data\n",
    "train_data, train_labels = read_data('./images_train.csv', './labels_train.csv')\n",
    "train_labels = one_hot_labels(train_labels)\n",
    "p = np.random.permutation(60000)\n",
    "train_data = train_data[p,:]\n",
    "train_labels = train_labels[p,:]\n",
    "\n",
    "dev_data = train_data[0:10000,:]\n",
    "dev_labels = train_labels[0:10000,:]\n",
    "train_data = train_data[10000:,:]\n",
    "train_labels = train_labels[10000:,:]\n",
    "\n",
    "mean = np.mean(train_data)\n",
    "std = np.std(train_data)\n",
    "train_data = (train_data - mean) / std\n",
    "dev_data = (dev_data - mean) / std\n",
    "\n",
    "test_data, test_labels = read_data('./images_test.csv', './labels_test.csv')\n",
    "test_labels = one_hot_labels(test_labels)\n",
    "test_data = (test_data - mean) / std\n",
    "\n",
    "all_data = {\n",
    "    'train': train_data,\n",
    "    'dev': dev_data,\n",
    "    'test': test_data\n",
    "}\n",
    "\n",
    "all_labels = {\n",
    "    'train': train_labels,\n",
    "    'dev': dev_labels,\n",
    "    'test': test_labels,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.01 Algo:  LMS\n",
      "0 / 20 train loss:  10.204900201891205 dev loss:  10.132572310751769\n",
      "1 / 20 train loss:  1.77381774199337 dev loss:  1.7997008359250648\n",
      "2 / 20 train loss:  1.2123975942633407 dev loss:  1.2508720976460128\n",
      "3 / 20 train loss:  0.9762246700161704 dev loss:  1.0293697369341044\n",
      "4 / 20 train loss:  0.8384820578757496 dev loss:  0.9058277132866149\n",
      "5 / 20 train loss:  0.7470643068842123 dev loss:  0.8253814543937362\n",
      "6 / 20 train loss:  0.6801689077519093 dev loss:  0.7678611893591891\n",
      "7 / 20 train loss:  0.6280132468244085 dev loss:  0.7247047981708373\n",
      "8 / 20 train loss:  0.5858908475264752 dev loss:  0.6901141651759847\n",
      "9 / 20 train loss:  0.551042533987409 dev loss:  0.6613671205944204\n",
      "10 / 20 train loss:  0.5216522383138016 dev loss:  0.6369414949683685\n",
      "11 / 20 train loss:  0.49642820305883756 dev loss:  0.615833972105072\n",
      "12 / 20 train loss:  0.4744800297083415 dev loss:  0.5973927824605616\n",
      "13 / 20 train loss:  0.4551364976559474 dev loss:  0.5811318308001704\n",
      "14 / 20 train loss:  0.4379050445034844 dev loss:  0.566639717114034\n",
      "15 / 20 train loss:  0.42244313051194765 dev loss:  0.5535980663096197\n",
      "16 / 20 train loss:  0.4084796516064111 dev loss:  0.5417509837733587\n",
      "17 / 20 train loss:  0.39579066483395764 dev loss:  0.5309117115475747\n",
      "18 / 20 train loss:  0.38419462592402037 dev loss:  0.5209472591524246\n",
      "19 / 20 train loss:  0.3735457624101224 dev loss:  0.5117597136446393\n",
      "For model LMS, got accuracy: 0.870700\n",
      "Learning rate:  0.05 Algo:  LMS\n",
      "0 / 20 train loss:  10.204900201891205 dev loss:  10.132572310751769\n",
      "1 / 20 train loss:  0.7446985786801352 dev loss:  0.8248596521764916\n",
      "2 / 20 train loss:  0.5184391474279093 dev loss:  0.6297063287953926\n",
      "3 / 20 train loss:  0.41930622887529445 dev loss:  0.5451400857389119\n",
      "4 / 20 train loss:  0.3613690974947709 dev loss:  0.49494885138261496\n",
      "5 / 20 train loss:  0.3220996726265512 dev loss:  0.46051551810878744\n",
      "6 / 20 train loss:  0.29323597578564115 dev loss:  0.43600836252917197\n",
      "7 / 20 train loss:  0.27130907374128327 dev loss:  0.41805406585551175\n",
      "8 / 20 train loss:  0.25391970186781754 dev loss:  0.4045263574907908\n",
      "9 / 20 train loss:  0.23955780214660474 dev loss:  0.3937816386626243\n",
      "10 / 20 train loss:  0.22730802313151827 dev loss:  0.38496433497936333\n",
      "11 / 20 train loss:  0.2166447760858544 dev loss:  0.37752318630889997\n",
      "12 / 20 train loss:  0.20725897753135342 dev loss:  0.3711847672985134\n",
      "13 / 20 train loss:  0.19884356455517035 dev loss:  0.36580611957107867\n",
      "14 / 20 train loss:  0.1911790947380102 dev loss:  0.3612261219645212\n",
      "15 / 20 train loss:  0.1841702590600802 dev loss:  0.3573142249894853\n",
      "16 / 20 train loss:  0.17775212285808004 dev loss:  0.3538472448227158\n",
      "17 / 20 train loss:  0.17184362211771403 dev loss:  0.3507341983641296\n",
      "18 / 20 train loss:  0.16638302956691478 dev loss:  0.3479875547490743\n",
      "19 / 20 train loss:  0.16131087229983285 dev loss:  0.3455427191046529\n",
      "For model LMS, got accuracy: 0.909300\n",
      "Learning rate:  0.1 Algo:  LMS\n",
      "0 / 20 train loss:  10.204900201891205 dev loss:  10.132572310751769\n",
      "1 / 20 train loss:  0.5344262030494117 dev loss:  0.6104168143196053\n",
      "2 / 20 train loss:  0.3640581481629952 dev loss:  0.473647739227048\n",
      "3 / 20 train loss:  0.2974254688021762 dev loss:  0.4173099756010801\n",
      "4 / 20 train loss:  0.25848019670597144 dev loss:  0.3839273468728111\n",
      "5 / 20 train loss:  0.23200170879456025 dev loss:  0.3627544843297116\n",
      "6 / 20 train loss:  0.21249272834603444 dev loss:  0.3486094947233066\n",
      "7 / 20 train loss:  0.19680513799664226 dev loss:  0.3385492464517677\n",
      "8 / 20 train loss:  0.18368681467285414 dev loss:  0.3311641970697244\n",
      "9 / 20 train loss:  0.17260946574259858 dev loss:  0.3257705453202246\n",
      "10 / 20 train loss:  0.16277945861816356 dev loss:  0.32132387484965147\n",
      "11 / 20 train loss:  0.15352623462929085 dev loss:  0.3169505215178623\n",
      "12 / 20 train loss:  0.14536926580419876 dev loss:  0.3138996779207047\n",
      "13 / 20 train loss:  0.13812380021500717 dev loss:  0.31192667333727037\n",
      "14 / 20 train loss:  0.13153524650599024 dev loss:  0.31049934215042924\n",
      "15 / 20 train loss:  0.12537414000424124 dev loss:  0.3093559456295848\n",
      "16 / 20 train loss:  0.11959322771752447 dev loss:  0.30846018856857527\n",
      "17 / 20 train loss:  0.11418225037653792 dev loss:  0.30792803900084076\n",
      "18 / 20 train loss:  0.10914020607119487 dev loss:  0.30772829040926747\n",
      "19 / 20 train loss:  0.10444757910089063 dev loss:  0.30772276600564813\n",
      "For model LMS, got accuracy: 0.917700\n",
      "Learning rate:  0.5 Algo:  LMS\n",
      "0 / 20 train loss:  10.204900201891205 dev loss:  10.132572310751769\n",
      "1 / 20 train loss:  0.2975358300014965 dev loss:  0.3462968803188257\n",
      "2 / 20 train loss:  0.23003129648720824 dev loss:  0.2969323436496112\n",
      "3 / 20 train loss:  0.17997529965245002 dev loss:  0.2718504567369945\n",
      "4 / 20 train loss:  0.13932821990078723 dev loss:  0.24863249647271427\n",
      "5 / 20 train loss:  0.11638040733719796 dev loss:  0.23321424613449918\n",
      "6 / 20 train loss:  0.09835733143751475 dev loss:  0.22901418490890796\n",
      "7 / 20 train loss:  0.0892318988068642 dev loss:  0.22932170905681268\n",
      "8 / 20 train loss:  0.08032447670675594 dev loss:  0.23394999908314518\n",
      "9 / 20 train loss:  0.07027068751144902 dev loss:  0.23971159814201382\n",
      "10 / 20 train loss:  0.06108361807360418 dev loss:  0.2406973356396402\n",
      "11 / 20 train loss:  0.053476100910326126 dev loss:  0.24184627843871032\n",
      "12 / 20 train loss:  0.046809193191778835 dev loss:  0.24334029206608349\n",
      "13 / 20 train loss:  0.043209829369229104 dev loss:  0.24869495756131418\n",
      "14 / 20 train loss:  0.03718325660430067 dev loss:  0.24922222154428714\n",
      "15 / 20 train loss:  0.034016548133865655 dev loss:  0.25348052682323935\n",
      "16 / 20 train loss:  0.03146700106429427 dev loss:  0.25758841130890203\n",
      "17 / 20 train loss:  0.028681182433278017 dev loss:  0.2592673262382883\n",
      "18 / 20 train loss:  0.02740017085551543 dev loss:  0.2645317426806747\n",
      "19 / 20 train loss:  0.02480208343787856 dev loss:  0.2670775659610023\n",
      "For model LMS, got accuracy: 0.942600\n",
      "Learning rate:  1 Algo:  LMS\n",
      "0 / 20 train loss:  10.204900201891205 dev loss:  10.132572310751769\n",
      "1 / 20 train loss:  0.3175522172925318 dev loss:  0.359214741939324\n",
      "2 / 20 train loss:  0.2209750439181758 dev loss:  0.27700005678902473\n",
      "3 / 20 train loss:  0.18619904346238883 dev loss:  0.24506420676810825\n",
      "4 / 20 train loss:  0.17100777677426274 dev loss:  0.24312088505255097\n",
      "5 / 20 train loss:  0.15303317815815926 dev loss:  0.22725676985243404\n",
      "6 / 20 train loss:  0.1247213680116616 dev loss:  0.20872048059918638\n",
      "7 / 20 train loss:  0.09829960611370024 dev loss:  0.19385205117513946\n",
      "8 / 20 train loss:  0.10035374364950485 dev loss:  0.20696693901704907\n",
      "9 / 20 train loss:  0.08359078707960849 dev loss:  0.18315989963527962\n",
      "10 / 20 train loss:  0.08360345169694693 dev loss:  0.19043719119009841\n",
      "11 / 20 train loss:  0.09009085609712852 dev loss:  0.20433883479759785\n",
      "12 / 20 train loss:  0.06618092769663166 dev loss:  0.17973980917031976\n",
      "13 / 20 train loss:  0.05290584979999716 dev loss:  0.17328735750167062\n",
      "14 / 20 train loss:  0.04905976973589827 dev loss:  0.17586806051834486\n",
      "15 / 20 train loss:  0.05344893285036588 dev loss:  0.18628304844937424\n",
      "16 / 20 train loss:  0.053769605868147136 dev loss:  0.18950277906715157\n",
      "17 / 20 train loss:  0.04503225004864312 dev loss:  0.19053864188789038\n",
      "18 / 20 train loss:  0.04375184207543681 dev loss:  0.1892848087461095\n",
      "19 / 20 train loss:  0.043626351184616524 dev loss:  0.1998553311722382\n",
      "For model LMS, got accuracy: 0.959100\n",
      "Learning rate:  2 Algo:  LMS\n",
      "0 / 20 train loss:  10.204900201891205 dev loss:  10.132572310751769\n",
      "1 / 20 train loss:  0.38843220187664934 dev loss:  0.4131357691222494\n",
      "2 / 20 train loss:  0.30515543489425007 dev loss:  0.35394214510216604\n",
      "3 / 20 train loss:  0.20858720745519102 dev loss:  0.255867943321861\n",
      "4 / 20 train loss:  0.1943839939773352 dev loss:  0.2436333108426715\n",
      "5 / 20 train loss:  0.18764059804579772 dev loss:  0.24768760787134997\n",
      "6 / 20 train loss:  0.17349813645686946 dev loss:  0.23053079150818784\n",
      "7 / 20 train loss:  0.16750901127701623 dev loss:  0.22975875357954714\n",
      "8 / 20 train loss:  0.1647177670268697 dev loss:  0.22083838536594835\n",
      "9 / 20 train loss:  0.142988700581087 dev loss:  0.2128028133683807\n",
      "10 / 20 train loss:  0.15023445551176862 dev loss:  0.21064333557769846\n",
      "11 / 20 train loss:  0.12918486807684054 dev loss:  0.194683229536947\n",
      "12 / 20 train loss:  0.12759581706930773 dev loss:  0.19328844395807865\n",
      "13 / 20 train loss:  0.1123147368208973 dev loss:  0.1875146435347177\n",
      "14 / 20 train loss:  0.133178288566356 dev loss:  0.21277704955928356\n",
      "15 / 20 train loss:  0.11377715901713222 dev loss:  0.1802189091458213\n",
      "16 / 20 train loss:  0.11179417426270954 dev loss:  0.1961293094252085\n",
      "17 / 20 train loss:  0.09890705081049386 dev loss:  0.183671430773706\n",
      "18 / 20 train loss:  0.08549900477410502 dev loss:  0.17065061179445096\n",
      "19 / 20 train loss:  0.10431157767675411 dev loss:  0.1873679028596692\n",
      "For model LMS, got accuracy: 0.952000\n",
      "Learning rate:  3 Algo:  LMS\n",
      "0 / 20 train loss:  10.204900201891205 dev loss:  10.132572310751769\n",
      "1 / 20 train loss:  0.7667090878909469 dev loss:  0.7910854942513857\n",
      "2 / 20 train loss:  0.3554327852460728 dev loss:  0.392974149514382\n",
      "3 / 20 train loss:  0.4099816563024444 dev loss:  0.4323425410096693\n",
      "4 / 20 train loss:  0.30881624722022794 dev loss:  0.342378084219696\n",
      "5 / 20 train loss:  0.2872141954378862 dev loss:  0.32533996657492337\n",
      "6 / 20 train loss:  0.2664584326575958 dev loss:  0.30709462142942695\n",
      "7 / 20 train loss:  0.24004130440571544 dev loss:  0.27870555992820867\n",
      "8 / 20 train loss:  0.22425964646326768 dev loss:  0.2839590258519494\n",
      "9 / 20 train loss:  0.21434990101323192 dev loss:  0.2768773384902557\n",
      "10 / 20 train loss:  0.26899225432793117 dev loss:  0.3357020335860229\n",
      "11 / 20 train loss:  0.19981749123635031 dev loss:  0.26453986798656376\n",
      "12 / 20 train loss:  0.17301802268049704 dev loss:  0.21733020415978835\n",
      "13 / 20 train loss:  0.1906936712446574 dev loss:  0.24938075482784147\n",
      "14 / 20 train loss:  0.17877820494931207 dev loss:  0.22850435360381835\n",
      "15 / 20 train loss:  0.16361096550584106 dev loss:  0.2265359821173929\n",
      "16 / 20 train loss:  0.1735874795635866 dev loss:  0.24796780329503867\n",
      "17 / 20 train loss:  0.1931165550292021 dev loss:  0.2611039871934155\n",
      "18 / 20 train loss:  0.14269877072855872 dev loss:  0.20926260378538636\n",
      "19 / 20 train loss:  0.15384279754611846 dev loss:  0.21741051392845107\n",
      "For model LMS, got accuracy: 0.943400\n",
      "Learning rate:  4 Algo:  LMS\n",
      "0 / 20 train loss:  10.204900201891205 dev loss:  10.132572310751769\n",
      "1 / 20 train loss:  1.489857379025792 dev loss:  1.5301471681393846\n",
      "2 / 20 train loss:  1.1411016177417426 dev loss:  1.1585994336993233\n",
      "3 / 20 train loss:  0.6495578821765928 dev loss:  0.6789648094304886\n",
      "4 / 20 train loss:  0.6230649521007644 dev loss:  0.6408613338272975\n",
      "5 / 20 train loss:  0.5144598938362053 dev loss:  0.5523291716190089\n",
      "6 / 20 train loss:  0.5070418050022082 dev loss:  0.5638631983126919\n",
      "7 / 20 train loss:  0.5506520451643366 dev loss:  0.5789383724126874\n",
      "8 / 20 train loss:  0.46558918580091485 dev loss:  0.529821078999953\n",
      "9 / 20 train loss:  0.3760333411272994 dev loss:  0.43981354750316404\n",
      "10 / 20 train loss:  0.34989165843918085 dev loss:  0.39031402855946046\n",
      "11 / 20 train loss:  0.3881962558130071 dev loss:  0.4210630781141932\n",
      "12 / 20 train loss:  0.3641657467455176 dev loss:  0.4031325295634702\n",
      "13 / 20 train loss:  0.34871903292156414 dev loss:  0.41814495246327577\n",
      "14 / 20 train loss:  0.431284298860442 dev loss:  0.5027803272681121\n",
      "15 / 20 train loss:  0.4259211259056809 dev loss:  0.5309057146170985\n",
      "16 / 20 train loss:  0.33002662068265265 dev loss:  0.4280277742577409\n",
      "17 / 20 train loss:  0.3603154990884427 dev loss:  0.4198505360310308\n",
      "18 / 20 train loss:  0.2725236083348295 dev loss:  0.3274769073652434\n",
      "19 / 20 train loss:  0.28315283721095597 dev loss:  0.36945631781783317\n",
      "For model LMS, got accuracy: 0.924900\n",
      "Learning rate:  5 Algo:  LMS\n",
      "0 / 20 train loss:  10.204900201891205 dev loss:  10.132572310751769\n",
      "1 / 20 train loss:  2.2173390962532364 dev loss:  2.297194783022534\n",
      "2 / 20 train loss:  1.922025053335444 dev loss:  1.911207972241912\n",
      "3 / 20 train loss:  1.8001158085795654 dev loss:  1.8307175287807007\n",
      "4 / 20 train loss:  1.6741210488747387 dev loss:  1.638705598642253\n",
      "5 / 20 train loss:  1.8145132914493525 dev loss:  1.824672599567135\n",
      "6 / 20 train loss:  1.68404129723317 dev loss:  1.7208385016267351\n",
      "7 / 20 train loss:  1.0044769941475182 dev loss:  1.0975219997513495\n",
      "8 / 20 train loss:  1.0254153260969978 dev loss:  1.0685339064490673\n",
      "9 / 20 train loss:  1.2228688059174877 dev loss:  1.2422802154780908\n",
      "10 / 20 train loss:  1.0037278571294521 dev loss:  1.0120254710499441\n",
      "11 / 20 train loss:  1.0977240089444427 dev loss:  1.2067075257960496\n",
      "12 / 20 train loss:  1.3254764583527614 dev loss:  1.3436036588910887\n",
      "13 / 20 train loss:  1.2749699667455283 dev loss:  1.4090254596188025\n",
      "14 / 20 train loss:  1.090970694464906 dev loss:  1.1354470475607423\n",
      "15 / 20 train loss:  1.47078442889909 dev loss:  1.5885551620379237\n",
      "16 / 20 train loss:  0.9913763692248688 dev loss:  1.0657392501270881\n",
      "17 / 20 train loss:  1.1355781307823596 dev loss:  1.2386840814023439\n",
      "18 / 20 train loss:  0.977812517188316 dev loss:  1.09455152973427\n",
      "19 / 20 train loss:  0.8309708225809931 dev loss:  0.892295616460129\n",
      "For model LMS, got accuracy: 0.894000\n",
      "Learning rate:  6 Algo:  LMS\n",
      "0 / 20 train loss:  10.204900201891205 dev loss:  10.132572310751769\n",
      "1 / 20 train loss:  3.366459576575837 dev loss:  3.348199087351851\n",
      "2 / 20 train loss:  5.122107574030268 dev loss:  5.176350589053203\n",
      "3 / 20 train loss:  3.466409916502123 dev loss:  3.5468885370208962\n",
      "4 / 20 train loss:  3.121619665863532 dev loss:  3.192105451124259\n",
      "5 / 20 train loss:  3.1944555754220354 dev loss:  3.219296105370415\n",
      "6 / 20 train loss:  2.2472032409523783 dev loss:  2.273271745634464\n",
      "7 / 20 train loss:  1.9912497379951837 dev loss:  2.080540514718654\n",
      "8 / 20 train loss:  2.1669254428687474 dev loss:  2.2526767699807375\n",
      "9 / 20 train loss:  2.0513727096479974 dev loss:  2.157925772380913\n",
      "10 / 20 train loss:  2.253556390780229 dev loss:  2.3250261477246954\n",
      "11 / 20 train loss:  2.7892376140554145 dev loss:  2.875869684682511\n",
      "12 / 20 train loss:  2.226907982640237 dev loss:  2.3683311023653726\n",
      "13 / 20 train loss:  2.2367365724042076 dev loss:  2.2356688340174955\n",
      "14 / 20 train loss:  2.4970166884822502 dev loss:  2.655662554155921\n",
      "15 / 20 train loss:  2.9062996775756385 dev loss:  2.9601413236870764\n",
      "16 / 20 train loss:  1.6783107363593892 dev loss:  1.774982315103872\n",
      "17 / 20 train loss:  1.5672936570856886 dev loss:  1.7118996044236436\n",
      "18 / 20 train loss:  1.7682586480228282 dev loss:  1.8680801170833008\n",
      "19 / 20 train loss:  2.0496611275076804 dev loss:  2.1396811171088252\n",
      "For model LMS, got accuracy: 0.858800\n",
      "Learning rate:  7 Algo:  LMS\n",
      "0 / 20 train loss:  10.204900201891205 dev loss:  10.132572310751769\n",
      "1 / 20 train loss:  2.514504589209022 dev loss:  2.4365725051629394\n",
      "2 / 20 train loss:  2.008943238874153 dev loss:  2.031146991168509\n",
      "3 / 20 train loss:  1.6004005027887693 dev loss:  1.645197506251315\n",
      "4 / 20 train loss:  1.5541182209232276 dev loss:  1.547590297074695\n",
      "5 / 20 train loss:  1.1946012156903085 dev loss:  1.1703633314762933\n",
      "6 / 20 train loss:  0.9555868810000341 dev loss:  0.9952412741817592\n",
      "7 / 20 train loss:  1.4723040025767198 dev loss:  1.4797542919597233\n",
      "8 / 20 train loss:  0.8840677487623524 dev loss:  0.8989070096730256\n",
      "9 / 20 train loss:  0.8097462500259418 dev loss:  0.8385907169897276\n",
      "10 / 20 train loss:  0.9037752041085608 dev loss:  0.912742899558552\n",
      "11 / 20 train loss:  0.8786592466995776 dev loss:  0.8967957468013872\n",
      "12 / 20 train loss:  0.7041930631860834 dev loss:  0.7110100244705605\n",
      "13 / 20 train loss:  0.5912256705771379 dev loss:  0.6314160961060187\n",
      "14 / 20 train loss:  0.6754098556253378 dev loss:  0.7412363854933892\n",
      "15 / 20 train loss:  0.6189960236970724 dev loss:  0.6780209901556342\n",
      "16 / 20 train loss:  0.608863760235087 dev loss:  0.6786223647968045\n",
      "17 / 20 train loss:  0.5784829842358271 dev loss:  0.6454293439419496\n",
      "18 / 20 train loss:  0.5657141684050361 dev loss:  0.6197119825020669\n",
      "19 / 20 train loss:  0.5943194650742338 dev loss:  0.6762072323150012\n",
      "For model LMS, got accuracy: 0.883800\n",
      "Learning rate:  8 Algo:  LMS\n",
      "0 / 20 train loss:  10.204900201891205 dev loss:  10.132572310751769\n",
      "1 / 20 train loss:  5.289526183578025 dev loss:  5.384407262843031\n",
      "2 / 20 train loss:  3.9216108529276763 dev loss:  3.8940824409942643\n",
      "3 / 20 train loss:  6.4328277823858455 dev loss:  6.248448417569763\n",
      "4 / 20 train loss:  4.543497410233642 dev loss:  4.57537647078817\n",
      "5 / 20 train loss:  8.557937917601004 dev loss:  8.66539775081939\n",
      "6 / 20 train loss:  5.986462838117311 dev loss:  6.046343116954914\n",
      "7 / 20 train loss:  3.7020222264883285 dev loss:  3.6891208402442164\n",
      "8 / 20 train loss:  3.810179316266311 dev loss:  3.877649925433121\n",
      "9 / 20 train loss:  3.042905852595326 dev loss:  3.0941074865008913\n",
      "10 / 20 train loss:  4.5763188721227275 dev loss:  4.522490897808062\n",
      "11 / 20 train loss:  3.76126056450725 dev loss:  3.683881074355099\n",
      "12 / 20 train loss:  4.439496981822427 dev loss:  4.514276661195868\n",
      "13 / 20 train loss:  3.7293443208260513 dev loss:  3.730027133526068\n",
      "14 / 20 train loss:  4.205210469248433 dev loss:  4.243939935772775\n",
      "15 / 20 train loss:  2.8863345307775847 dev loss:  2.924872037391779\n",
      "16 / 20 train loss:  2.660894298393253 dev loss:  2.8803963430364807\n",
      "17 / 20 train loss:  2.3866874523420374 dev loss:  2.52653659585652\n",
      "18 / 20 train loss:  2.637870922238255 dev loss:  2.6611595349557713\n",
      "19 / 20 train loss:  2.3577307466281825 dev loss:  2.380059417805161\n",
      "For model LMS, got accuracy: 0.883000\n",
      "Learning rate:  9 Algo:  LMS\n",
      "0 / 20 train loss:  10.204900201891205 dev loss:  10.132572310751769\n",
      "1 / 20 train loss:  7.15937541405701 dev loss:  7.265365393013751\n",
      "2 / 20 train loss:  7.627040645693041 dev loss:  7.602787635573231\n",
      "3 / 20 train loss:  7.799306156964221 dev loss:  7.670995020084524\n",
      "4 / 20 train loss:  4.443543932247439 dev loss:  4.331039870570576\n",
      "5 / 20 train loss:  5.051446135397562 dev loss:  5.304298183829764\n",
      "6 / 20 train loss:  5.388315607512478 dev loss:  5.414590781036373\n",
      "7 / 20 train loss:  10.078771959921507 dev loss:  9.978584549467252\n",
      "8 / 20 train loss:  4.593322370654917 dev loss:  4.824361594573532\n",
      "9 / 20 train loss:  4.305108825738535 dev loss:  4.391618406312514\n",
      "10 / 20 train loss:  4.144152742537619 dev loss:  4.084606772286602\n",
      "11 / 20 train loss:  4.616204081946505 dev loss:  4.561506444358097\n",
      "12 / 20 train loss:  4.877442072432192 dev loss:  5.137517854045848\n",
      "13 / 20 train loss:  4.300606580942404 dev loss:  4.409933994308204\n",
      "14 / 20 train loss:  3.5076935214226803 dev loss:  3.498776079067197\n",
      "15 / 20 train loss:  3.920981599133295 dev loss:  3.9752216369007174\n",
      "16 / 20 train loss:  3.5325422371639776 dev loss:  3.503922268390933\n",
      "17 / 20 train loss:  3.7973562072777542 dev loss:  3.896720207180291\n",
      "18 / 20 train loss:  6.947955179684991 dev loss:  6.895188937002202\n",
      "19 / 20 train loss:  2.946791107722773 dev loss:  2.938954556140084\n",
      "For model LMS, got accuracy: 0.839400\n",
      "Learning rate:  10 Algo:  LMS\n",
      "0 / 20 train loss:  10.204900201891205 dev loss:  10.132572310751769\n",
      "1 / 20 train loss:  9.365736119517061 dev loss:  9.302034363650726\n",
      "2 / 20 train loss:  4.695724207564301 dev loss:  4.717555783398319\n",
      "3 / 20 train loss:  5.433630416501511 dev loss:  5.360466940021368\n",
      "4 / 20 train loss:  6.317622314661271 dev loss:  6.497856816752486\n",
      "5 / 20 train loss:  5.0770858886915295 dev loss:  4.994568097468785\n",
      "6 / 20 train loss:  9.192353214025227 dev loss:  9.095300410225512\n",
      "7 / 20 train loss:  7.066125685540009 dev loss:  7.1148346826234325\n",
      "8 / 20 train loss:  5.632828550665687 dev loss:  5.6019000460319734\n",
      "9 / 20 train loss:  7.111085555976993 dev loss:  7.089559750649559\n",
      "10 / 20 train loss:  4.172838204299712 dev loss:  4.313662515366094\n",
      "11 / 20 train loss:  5.108517654640339 dev loss:  5.155127854886506\n",
      "12 / 20 train loss:  4.32432726435795 dev loss:  4.236380827913737\n",
      "13 / 20 train loss:  5.518041514859806 dev loss:  5.501372206856794\n",
      "14 / 20 train loss:  5.171451320488587 dev loss:  5.131663300660647\n",
      "15 / 20 train loss:  5.8763835441795305 dev loss:  6.022214989465612\n",
      "16 / 20 train loss:  5.112548517309203 dev loss:  5.042478540037119\n",
      "17 / 20 train loss:  5.015549963329291 dev loss:  4.872931680386458\n",
      "18 / 20 train loss:  5.450824155163868 dev loss:  5.523101251194743\n",
      "19 / 20 train loss:  3.507336056973992 dev loss:  3.469173558033381\n",
      "For model LMS, got accuracy: 0.845100\n",
      "Learning rate:  0.01 Algo:  %LMS\n",
      "0 / 20 train loss:  10.204900201891205 dev loss:  10.132572310751769\n",
      "1 / 20 train loss:  2.0128782211915492 dev loss:  2.037198396152276\n",
      "2 / 20 train loss:  1.3744370895536413 dev loss:  1.4161090836887478\n",
      "3 / 20 train loss:  1.1052671912337493 dev loss:  1.1601094472631917\n",
      "4 / 20 train loss:  0.951545832565534 dev loss:  1.016336243961537\n",
      "5 / 20 train loss:  0.8487513250162895 dev loss:  0.9216459018447144\n",
      "6 / 20 train loss:  0.7742882993450704 dev loss:  0.8539502333774841\n",
      "7 / 20 train loss:  0.7170938451244644 dev loss:  0.8029867929457272\n",
      "8 / 20 train loss:  0.6713045094407535 dev loss:  0.7627966453807883\n",
      "9 / 20 train loss:  0.6334949976821757 dev loss:  0.7299499060564967\n",
      "10 / 20 train loss:  0.6015985984972396 dev loss:  0.7023078715442136\n",
      "11 / 20 train loss:  0.5742396305868044 dev loss:  0.6785206408460014\n",
      "12 / 20 train loss:  0.5504650560533259 dev loss:  0.6577466762366384\n",
      "13 / 20 train loss:  0.5295759898538525 dev loss:  0.6394505113991814\n",
      "14 / 20 train loss:  0.511017869362265 dev loss:  0.6232064451044029\n",
      "15 / 20 train loss:  0.4943580663125217 dev loss:  0.6086622563250097\n",
      "16 / 20 train loss:  0.47927563751037267 dev loss:  0.5955335662597139\n",
      "17 / 20 train loss:  0.46553184004583537 dev loss:  0.5835972542678507\n",
      "18 / 20 train loss:  0.4529433451015693 dev loss:  0.5726803896258011\n",
      "19 / 20 train loss:  0.4413626275406849 dev loss:  0.5626445069450526\n",
      "For model %LMS, got accuracy: 0.855500\n",
      "Learning rate:  0.05 Algo:  %LMS\n",
      "0 / 20 train loss:  10.204900201891205 dev loss:  10.132572310751769\n",
      "1 / 20 train loss:  0.8346042899720645 dev loss:  0.9028691623326542\n",
      "2 / 20 train loss:  0.5875160206716182 dev loss:  0.6835154339080987\n",
      "3 / 20 train loss:  0.4834425942531626 dev loss:  0.5902847242541751\n",
      "4 / 20 train loss:  0.42225252445916384 dev loss:  0.5357940516033919\n",
      "5 / 20 train loss:  0.3800700378660722 dev loss:  0.49934303080895204\n",
      "6 / 20 train loss:  0.34914274356448427 dev loss:  0.47299977990804226\n",
      "7 / 20 train loss:  0.3255813263356401 dev loss:  0.45332862295595433\n",
      "8 / 20 train loss:  0.30666124297514175 dev loss:  0.43775185512691006\n",
      "9 / 20 train loss:  0.2907791479129914 dev loss:  0.4246765810325296\n",
      "10 / 20 train loss:  0.2771378693837909 dev loss:  0.4135918852373119\n",
      "11 / 20 train loss:  0.2653199419301084 dev loss:  0.40426179249649347\n",
      "12 / 20 train loss:  0.25490717831129833 dev loss:  0.39630147751174577\n",
      "13 / 20 train loss:  0.2455801111419691 dev loss:  0.38943789762278064\n",
      "14 / 20 train loss:  0.237122231325022 dev loss:  0.38340212205753216\n",
      "15 / 20 train loss:  0.22944034561320717 dev loss:  0.3779720427869578\n",
      "16 / 20 train loss:  0.22239415247484884 dev loss:  0.3730318102714595\n",
      "17 / 20 train loss:  0.21587970390510947 dev loss:  0.368558321386508\n",
      "18 / 20 train loss:  0.2098508352937125 dev loss:  0.3645700899256709\n",
      "19 / 20 train loss:  0.20425841481546078 dev loss:  0.3610258855268068\n",
      "For model %LMS, got accuracy: 0.896400\n",
      "Learning rate:  0.1 Algo:  %LMS\n",
      "0 / 20 train loss:  10.204900201891205 dev loss:  10.132572310751769\n",
      "1 / 20 train loss:  0.6024425047624625 dev loss:  0.6739991612622324\n",
      "2 / 20 train loss:  0.4280717095589425 dev loss:  0.5236117956547861\n",
      "3 / 20 train loss:  0.353341333153831 dev loss:  0.4611266775304449\n",
      "4 / 20 train loss:  0.3095574344780967 dev loss:  0.4247795094742065\n",
      "5 / 20 train loss:  0.28049228556463984 dev loss:  0.4013847352677266\n",
      "6 / 20 train loss:  0.25871258519508394 dev loss:  0.385251865370227\n",
      "7 / 20 train loss:  0.2414738803699172 dev loss:  0.3730848782386176\n",
      "8 / 20 train loss:  0.22713323970905178 dev loss:  0.36297001993714706\n",
      "9 / 20 train loss:  0.21480930876927862 dev loss:  0.35476505319122964\n",
      "10 / 20 train loss:  0.2040698726499462 dev loss:  0.3481122778536325\n",
      "11 / 20 train loss:  0.1945867994616192 dev loss:  0.3425778628659375\n",
      "12 / 20 train loss:  0.18614535083700168 dev loss:  0.3380062578954358\n",
      "13 / 20 train loss:  0.17850465049866204 dev loss:  0.3341340643023664\n",
      "14 / 20 train loss:  0.1715309466863389 dev loss:  0.33076875647282683\n",
      "15 / 20 train loss:  0.16510694707789625 dev loss:  0.3278908730846882\n",
      "16 / 20 train loss:  0.1591728837735435 dev loss:  0.3255703216344287\n",
      "17 / 20 train loss:  0.1536652189536619 dev loss:  0.32374285284251025\n",
      "18 / 20 train loss:  0.14850366188147304 dev loss:  0.32229616447018816\n",
      "19 / 20 train loss:  0.14365761623040843 dev loss:  0.3210873016179855\n",
      "For model %LMS, got accuracy: 0.912700\n",
      "Learning rate:  0.5 Algo:  %LMS\n",
      "0 / 20 train loss:  10.204900201891205 dev loss:  10.132572310751769\n",
      "1 / 20 train loss:  0.3210100384506072 dev loss:  0.37372841307095483\n",
      "2 / 20 train loss:  0.22932081124653808 dev loss:  0.3032494633520373\n",
      "3 / 20 train loss:  0.1882371399891317 dev loss:  0.2764415688846123\n",
      "4 / 20 train loss:  0.16563614240698643 dev loss:  0.26680116496508255\n",
      "5 / 20 train loss:  0.14735537261289738 dev loss:  0.2563382692076169\n",
      "6 / 20 train loss:  0.136092402075028 dev loss:  0.2534173585111086\n",
      "7 / 20 train loss:  0.1242224629638562 dev loss:  0.25330851628243456\n",
      "8 / 20 train loss:  0.11100802361921522 dev loss:  0.2494576785227761\n",
      "9 / 20 train loss:  0.10134226051700354 dev loss:  0.2478161232377684\n",
      "10 / 20 train loss:  0.09385131216570702 dev loss:  0.24850504009142177\n",
      "11 / 20 train loss:  0.09060189520307045 dev loss:  0.25313797673381466\n",
      "12 / 20 train loss:  0.08229694053785568 dev loss:  0.2530410310811615\n",
      "13 / 20 train loss:  0.07609943451972062 dev loss:  0.2554555048816897\n",
      "14 / 20 train loss:  0.06768211184052635 dev loss:  0.2568877854543289\n",
      "15 / 20 train loss:  0.06218112430721713 dev loss:  0.26210017277443565\n",
      "16 / 20 train loss:  0.05805103410246899 dev loss:  0.2657052443607854\n",
      "17 / 20 train loss:  0.05583413774599961 dev loss:  0.27092910522349056\n",
      "18 / 20 train loss:  0.05226254130177159 dev loss:  0.2745433138202388\n",
      "19 / 20 train loss:  0.048335237672699725 dev loss:  0.27745620535127447\n",
      "For model %LMS, got accuracy: 0.937600\n",
      "Learning rate:  1 Algo:  %LMS\n",
      "0 / 20 train loss:  10.204900201891205 dev loss:  10.132572310751769\n",
      "1 / 20 train loss:  0.2588524232759519 dev loss:  0.2928233774660974\n",
      "2 / 20 train loss:  0.1974419144265213 dev loss:  0.24828745006307096\n",
      "3 / 20 train loss:  0.15935629887541167 dev loss:  0.2129591302098978\n",
      "4 / 20 train loss:  0.1357798009519521 dev loss:  0.20808051392515353\n",
      "5 / 20 train loss:  0.11749124487804889 dev loss:  0.20282666697968763\n",
      "6 / 20 train loss:  0.10358006969785281 dev loss:  0.20027665895557945\n",
      "7 / 20 train loss:  0.09357633696000525 dev loss:  0.19898572015922364\n",
      "8 / 20 train loss:  0.08485790740546248 dev loss:  0.19769500294736442\n",
      "9 / 20 train loss:  0.07947664322975587 dev loss:  0.20399767314221032\n",
      "10 / 20 train loss:  0.07478422477998217 dev loss:  0.2075860649760042\n",
      "11 / 20 train loss:  0.06260481832712654 dev loss:  0.19976396547721403\n",
      "12 / 20 train loss:  0.0596416815687258 dev loss:  0.20666962615787723\n",
      "13 / 20 train loss:  0.05482740700911066 dev loss:  0.20697589430833135\n",
      "14 / 20 train loss:  0.04743440884018176 dev loss:  0.21358055120921285\n",
      "15 / 20 train loss:  0.049235082585731144 dev loss:  0.2167003512709909\n",
      "16 / 20 train loss:  0.04224224883120063 dev loss:  0.2144032200419213\n",
      "17 / 20 train loss:  0.04366030161548563 dev loss:  0.2260429805696265\n",
      "18 / 20 train loss:  0.040887820554262974 dev loss:  0.23286891288539147\n",
      "19 / 20 train loss:  0.038979169007992163 dev loss:  0.2285764074349785\n",
      "For model %LMS, got accuracy: 0.949300\n",
      "Learning rate:  2 Algo:  %LMS\n",
      "0 / 20 train loss:  10.204900201891205 dev loss:  10.132572310751769\n",
      "1 / 20 train loss:  0.2552863588779627 dev loss:  0.28666820189332576\n",
      "2 / 20 train loss:  0.19703123603470576 dev loss:  0.2444474680914056\n",
      "3 / 20 train loss:  0.15839133310154427 dev loss:  0.213239122882474\n",
      "4 / 20 train loss:  0.1339828384174548 dev loss:  0.19193259012911748\n",
      "5 / 20 train loss:  0.12739551214288106 dev loss:  0.19491652630779072\n",
      "6 / 20 train loss:  0.10952280458639259 dev loss:  0.17294979061371601\n",
      "7 / 20 train loss:  0.10156628244247806 dev loss:  0.17574997695151898\n",
      "8 / 20 train loss:  0.09095013691393322 dev loss:  0.16037660895944758\n",
      "9 / 20 train loss:  0.09278782601536488 dev loss:  0.16758888841630157\n",
      "10 / 20 train loss:  0.07661943182044019 dev loss:  0.1594532613702343\n",
      "11 / 20 train loss:  0.07297593115537912 dev loss:  0.16007692312162672\n",
      "12 / 20 train loss:  0.06876308318553154 dev loss:  0.157309057383961\n",
      "13 / 20 train loss:  0.06759291122465172 dev loss:  0.16234118170897072\n",
      "14 / 20 train loss:  0.06628639588809397 dev loss:  0.16854146460994296\n",
      "15 / 20 train loss:  0.06703296907940777 dev loss:  0.17168992068828928\n",
      "16 / 20 train loss:  0.06641729249708968 dev loss:  0.17518172435646534\n",
      "17 / 20 train loss:  0.061537382439095074 dev loss:  0.16575785105727256\n",
      "18 / 20 train loss:  0.054844644685806264 dev loss:  0.16556451385074128\n",
      "19 / 20 train loss:  0.06186769637143362 dev loss:  0.1762217183536944\n",
      "For model %LMS, got accuracy: 0.957200\n",
      "Learning rate:  3 Algo:  %LMS\n",
      "0 / 20 train loss:  10.204900201891205 dev loss:  10.132572310751769\n",
      "1 / 20 train loss:  0.2696066999008095 dev loss:  0.29121819789506387\n",
      "2 / 20 train loss:  0.19988033778817976 dev loss:  0.22561568961161294\n",
      "3 / 20 train loss:  0.16293551180065416 dev loss:  0.19359677117224028\n",
      "4 / 20 train loss:  0.1435306401135837 dev loss:  0.18984195751174004\n",
      "5 / 20 train loss:  0.12931041003675012 dev loss:  0.17552033913918805\n",
      "6 / 20 train loss:  0.12017370248449499 dev loss:  0.16657529592729023\n",
      "7 / 20 train loss:  0.11800616239348254 dev loss:  0.15843964013879672\n",
      "8 / 20 train loss:  0.10605358920445719 dev loss:  0.15658749084483453\n",
      "9 / 20 train loss:  0.09735622489373699 dev loss:  0.15776921555294163\n",
      "10 / 20 train loss:  0.09542427953473288 dev loss:  0.1551533546650703\n",
      "11 / 20 train loss:  0.08625373542842954 dev loss:  0.1504948077482841\n",
      "12 / 20 train loss:  0.0758813266695338 dev loss:  0.14063622443420637\n",
      "13 / 20 train loss:  0.07359734571945163 dev loss:  0.1463425845513974\n",
      "14 / 20 train loss:  0.07650896944686976 dev loss:  0.147639035018294\n",
      "15 / 20 train loss:  0.07166049735324544 dev loss:  0.1542278944333692\n",
      "16 / 20 train loss:  0.0710221365820377 dev loss:  0.1379085668356488\n",
      "17 / 20 train loss:  0.07055770614627291 dev loss:  0.14676239996855447\n",
      "18 / 20 train loss:  0.06407322075329042 dev loss:  0.1444644371657532\n",
      "19 / 20 train loss:  0.059618944402377194 dev loss:  0.14128693466236336\n",
      "For model %LMS, got accuracy: 0.963600\n",
      "Learning rate:  4 Algo:  %LMS\n",
      "0 / 20 train loss:  10.204900201891205 dev loss:  10.132572310751769\n",
      "1 / 20 train loss:  0.28467490945973006 dev loss:  0.3072315633131794\n",
      "2 / 20 train loss:  0.21127072285038878 dev loss:  0.23639927104966604\n",
      "3 / 20 train loss:  0.17932315810133037 dev loss:  0.20544350981394924\n",
      "4 / 20 train loss:  0.15693877554073277 dev loss:  0.18291632070171354\n",
      "5 / 20 train loss:  0.1468294309057322 dev loss:  0.17668322374945017\n",
      "6 / 20 train loss:  0.1402885468738126 dev loss:  0.175605682118786\n",
      "7 / 20 train loss:  0.1285184221402389 dev loss:  0.16391760558651997\n",
      "8 / 20 train loss:  0.11765672303257592 dev loss:  0.16114912616811666\n",
      "9 / 20 train loss:  0.11725213828889851 dev loss:  0.1562153544459309\n",
      "10 / 20 train loss:  0.11596922250944568 dev loss:  0.1572840513184349\n",
      "11 / 20 train loss:  0.1051077998311254 dev loss:  0.15291591294589527\n",
      "12 / 20 train loss:  0.10158206444381314 dev loss:  0.15125521846479725\n",
      "13 / 20 train loss:  0.09888174759180725 dev loss:  0.1497529578394367\n",
      "14 / 20 train loss:  0.08904859364051788 dev loss:  0.1438498000291697\n",
      "15 / 20 train loss:  0.09064026684362064 dev loss:  0.13431648370257157\n",
      "16 / 20 train loss:  0.08601269159502041 dev loss:  0.1388795138598569\n",
      "17 / 20 train loss:  0.08551801184597056 dev loss:  0.14180007856233842\n",
      "18 / 20 train loss:  0.0777649802680423 dev loss:  0.13355902781536855\n",
      "19 / 20 train loss:  0.07922500942445322 dev loss:  0.1316675787099467\n",
      "For model %LMS, got accuracy: 0.961300\n",
      "Learning rate:  5 Algo:  %LMS\n",
      "0 / 20 train loss:  10.204900201891205 dev loss:  10.132572310751769\n",
      "1 / 20 train loss:  0.288424605188586 dev loss:  0.3080986271874341\n",
      "2 / 20 train loss:  0.22908659684262403 dev loss:  0.25891603181053463\n",
      "3 / 20 train loss:  0.21266580562084994 dev loss:  0.23978504133786946\n",
      "4 / 20 train loss:  0.19566147134918682 dev loss:  0.2265585136134833\n",
      "5 / 20 train loss:  0.1666076434767758 dev loss:  0.18975340076484523\n",
      "6 / 20 train loss:  0.16477997382519718 dev loss:  0.19267607022921177\n",
      "7 / 20 train loss:  0.16118976649854985 dev loss:  0.18788619241254773\n",
      "8 / 20 train loss:  0.1511167082828931 dev loss:  0.18061446678588014\n",
      "9 / 20 train loss:  0.13865113733604953 dev loss:  0.16800530829545976\n",
      "10 / 20 train loss:  0.13954615997312353 dev loss:  0.17336470082210875\n",
      "11 / 20 train loss:  0.13483747216338407 dev loss:  0.1734103267471609\n",
      "12 / 20 train loss:  0.12913009535022024 dev loss:  0.17132390351841076\n",
      "13 / 20 train loss:  0.12276556539526873 dev loss:  0.16318403864137795\n",
      "14 / 20 train loss:  0.11494860691571894 dev loss:  0.161005215761405\n",
      "15 / 20 train loss:  0.10768508879850994 dev loss:  0.15046393186208612\n",
      "16 / 20 train loss:  0.11382606506725376 dev loss:  0.15882629861940856\n",
      "17 / 20 train loss:  0.11461694607223605 dev loss:  0.15932329334778864\n",
      "18 / 20 train loss:  0.1021631916971104 dev loss:  0.14944492183217722\n",
      "19 / 20 train loss:  0.10837066449743575 dev loss:  0.15399062946979541\n",
      "For model %LMS, got accuracy: 0.958000\n",
      "Learning rate:  6 Algo:  %LMS\n",
      "0 / 20 train loss:  10.204900201891205 dev loss:  10.132572310751769\n",
      "1 / 20 train loss:  0.335054785570881 dev loss:  0.3484562902928843\n",
      "2 / 20 train loss:  0.28037884391880014 dev loss:  0.30027554518423366\n",
      "3 / 20 train loss:  0.2508186434146606 dev loss:  0.2843123693769828\n",
      "4 / 20 train loss:  0.2247672001801726 dev loss:  0.25244536029131853\n",
      "5 / 20 train loss:  0.20077091563527977 dev loss:  0.23021012772674093\n",
      "6 / 20 train loss:  0.1842129532323088 dev loss:  0.22300070918380607\n",
      "7 / 20 train loss:  0.17317555596261197 dev loss:  0.21415640526535568\n",
      "8 / 20 train loss:  0.1685090849106045 dev loss:  0.20369342804788665\n",
      "9 / 20 train loss:  0.15935147532319022 dev loss:  0.19681037157106113\n",
      "10 / 20 train loss:  0.16323691844091867 dev loss:  0.19298048283231323\n",
      "11 / 20 train loss:  0.14351398926837572 dev loss:  0.18112068954285235\n",
      "12 / 20 train loss:  0.14969487397180817 dev loss:  0.18465968884862224\n",
      "13 / 20 train loss:  0.146571342869872 dev loss:  0.18417775896274816\n",
      "14 / 20 train loss:  0.13462752177279266 dev loss:  0.17581152686516907\n",
      "15 / 20 train loss:  0.14011324542125192 dev loss:  0.1780164593278254\n",
      "16 / 20 train loss:  0.13209564685641298 dev loss:  0.18360807474543778\n",
      "17 / 20 train loss:  0.13170566873121084 dev loss:  0.17457261977702884\n",
      "18 / 20 train loss:  0.13458419040314085 dev loss:  0.1777535111493452\n",
      "19 / 20 train loss:  0.1334850084072496 dev loss:  0.17017821149468537\n",
      "For model %LMS, got accuracy: 0.950100\n",
      "Learning rate:  7 Algo:  %LMS\n",
      "0 / 20 train loss:  10.204900201891205 dev loss:  10.132572310751769\n",
      "1 / 20 train loss:  0.38896255899100024 dev loss:  0.40437269073365706\n",
      "2 / 20 train loss:  0.29700091004914314 dev loss:  0.3131739743132724\n",
      "3 / 20 train loss:  0.27241005789542666 dev loss:  0.29021699466100936\n",
      "4 / 20 train loss:  0.26050296517253924 dev loss:  0.2681994031555355\n",
      "5 / 20 train loss:  0.25323985626926804 dev loss:  0.2796717576993731\n",
      "6 / 20 train loss:  0.22294533567747038 dev loss:  0.25373277936422556\n",
      "7 / 20 train loss:  0.22288331337023368 dev loss:  0.25804561120077435\n",
      "8 / 20 train loss:  0.2384378415530411 dev loss:  0.26578606177294767\n",
      "9 / 20 train loss:  0.21902163480452494 dev loss:  0.24378180696126991\n",
      "10 / 20 train loss:  0.1990781275501339 dev loss:  0.2262516599288555\n",
      "11 / 20 train loss:  0.20906408946487925 dev loss:  0.23291487292131577\n",
      "12 / 20 train loss:  0.1898291517133535 dev loss:  0.2195558998212019\n",
      "13 / 20 train loss:  0.18405889767506836 dev loss:  0.21308570849886246\n",
      "14 / 20 train loss:  0.18879954087212947 dev loss:  0.2206907173591822\n",
      "15 / 20 train loss:  0.18606211078163823 dev loss:  0.2226764365298598\n",
      "16 / 20 train loss:  0.18208448935771357 dev loss:  0.21753023571305274\n",
      "17 / 20 train loss:  0.17937897409096226 dev loss:  0.22022559344967335\n",
      "18 / 20 train loss:  0.1751701795137687 dev loss:  0.21490265436120057\n",
      "19 / 20 train loss:  0.17952218480001614 dev loss:  0.21496641285411192\n",
      "For model %LMS, got accuracy: 0.945100\n",
      "Learning rate:  8 Algo:  %LMS\n",
      "0 / 20 train loss:  10.204900201891205 dev loss:  10.132572310751769\n",
      "1 / 20 train loss:  0.4332877246259679 dev loss:  0.4450570140615705\n",
      "2 / 20 train loss:  0.37556742125160053 dev loss:  0.39625600131374006\n",
      "3 / 20 train loss:  0.3675110241421193 dev loss:  0.3875881562891426\n",
      "4 / 20 train loss:  0.30322933311565964 dev loss:  0.32983063107664523\n",
      "5 / 20 train loss:  0.3023689413767559 dev loss:  0.31355578259095745\n",
      "6 / 20 train loss:  0.280679247102559 dev loss:  0.30713268845836467\n",
      "7 / 20 train loss:  0.298235840674658 dev loss:  0.3185604147320573\n",
      "8 / 20 train loss:  0.28202871666582924 dev loss:  0.31534618274423726\n",
      "9 / 20 train loss:  0.27995967229260865 dev loss:  0.30826039356679963\n",
      "10 / 20 train loss:  0.296304207674325 dev loss:  0.3235387700018093\n",
      "11 / 20 train loss:  0.2671732836407836 dev loss:  0.29105284291580313\n",
      "12 / 20 train loss:  0.26365858141456217 dev loss:  0.2850818295446939\n",
      "13 / 20 train loss:  0.27871097911575304 dev loss:  0.2974249765400399\n",
      "14 / 20 train loss:  0.306008495437777 dev loss:  0.34057996186655426\n",
      "15 / 20 train loss:  0.28112592009354753 dev loss:  0.310414457391534\n",
      "16 / 20 train loss:  0.27855776458473286 dev loss:  0.31358687541203645\n",
      "17 / 20 train loss:  0.2845104624690588 dev loss:  0.3242342990546606\n",
      "18 / 20 train loss:  0.297521416177571 dev loss:  0.32230615971944204\n",
      "19 / 20 train loss:  0.2643505545539981 dev loss:  0.300184387339191\n",
      "For model %LMS, got accuracy: 0.920800\n",
      "Learning rate:  9 Algo:  %LMS\n",
      "0 / 20 train loss:  10.204900201891205 dev loss:  10.132572310751769\n",
      "1 / 20 train loss:  1.0307655920255212 dev loss:  0.9932184056304323\n",
      "2 / 20 train loss:  0.8736192515190471 dev loss:  0.8485211912265742\n",
      "3 / 20 train loss:  0.8373348651612228 dev loss:  0.8026951744462917\n",
      "4 / 20 train loss:  0.7754987002226243 dev loss:  0.7544055211413326\n",
      "5 / 20 train loss:  0.66798426391797 dev loss:  0.6546103881187475\n",
      "6 / 20 train loss:  0.7099654700499347 dev loss:  0.7096784384032306\n",
      "7 / 20 train loss:  0.6349160109445551 dev loss:  0.6403846454183949\n",
      "8 / 20 train loss:  0.6187674444795738 dev loss:  0.616651021657403\n",
      "9 / 20 train loss:  0.6391594029821184 dev loss:  0.6472114619860129\n",
      "10 / 20 train loss:  0.6475787914428994 dev loss:  0.6544778022527795\n",
      "11 / 20 train loss:  0.6731588571393458 dev loss:  0.6896656571275649\n",
      "12 / 20 train loss:  0.6328666561205563 dev loss:  0.6482923964103394\n",
      "13 / 20 train loss:  0.6019097704944271 dev loss:  0.6149378922705927\n",
      "14 / 20 train loss:  0.5719040126610215 dev loss:  0.5912544674059343\n",
      "15 / 20 train loss:  0.6066933496488445 dev loss:  0.6252229886045773\n",
      "16 / 20 train loss:  0.6164877149819047 dev loss:  0.6315036874352431\n",
      "17 / 20 train loss:  0.6077130257715927 dev loss:  0.6199129581952538\n",
      "18 / 20 train loss:  0.6174283781600348 dev loss:  0.61674501220331\n",
      "19 / 20 train loss:  0.7325555441003375 dev loss:  0.7484793940238763\n",
      "For model %LMS, got accuracy: 0.786900\n",
      "Learning rate:  10 Algo:  %LMS\n",
      "0 / 20 train loss:  10.204900201891205 dev loss:  10.132572310751769\n",
      "1 / 20 train loss:  0.6170511907361741 dev loss:  0.6298541979489777\n",
      "2 / 20 train loss:  0.5201248418674164 dev loss:  0.5268453495725679\n",
      "3 / 20 train loss:  0.46244665788161915 dev loss:  0.4674377391857235\n",
      "4 / 20 train loss:  0.5273424982819886 dev loss:  0.5455339919371308\n",
      "5 / 20 train loss:  0.4892203040084554 dev loss:  0.4965977400492379\n",
      "6 / 20 train loss:  0.4977802885259963 dev loss:  0.5169041270669471\n",
      "7 / 20 train loss:  0.44009043490929634 dev loss:  0.4631304343591303\n",
      "8 / 20 train loss:  0.4727100262917572 dev loss:  0.48341119863481635\n",
      "9 / 20 train loss:  0.45269780759595835 dev loss:  0.4742906587756123\n",
      "10 / 20 train loss:  0.4762965802531896 dev loss:  0.4900988638974566\n",
      "11 / 20 train loss:  0.43935079451066056 dev loss:  0.4417294912323825\n",
      "12 / 20 train loss:  0.4074765820385793 dev loss:  0.4184059716137715\n",
      "13 / 20 train loss:  0.44206185130230957 dev loss:  0.462223902985178\n",
      "14 / 20 train loss:  0.4839109313884645 dev loss:  0.4999114366796111\n",
      "15 / 20 train loss:  0.43620722055538863 dev loss:  0.4578517460271105\n",
      "16 / 20 train loss:  0.4097425348297221 dev loss:  0.4326627636594079\n",
      "17 / 20 train loss:  0.42964054752276953 dev loss:  0.4511902598712042\n",
      "18 / 20 train loss:  0.3613489375964444 dev loss:  0.39156735394695436\n",
      "19 / 20 train loss:  0.42238837542637475 dev loss:  0.4392697097790558\n",
      "For model %LMS, got accuracy: 0.877800\n"
     ]
    }
   ],
   "source": [
    "# Search through learning rates\n",
    "lrs = [0.01, 0.05, 0.1, 0.5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "results = {}\n",
    "num_epochs = 20\n",
    "plot = False\n",
    "\n",
    "algos = ['LMS', '%LMS']\n",
    "\n",
    "for algo in algos:\n",
    "    algo_dict = defaultdict(list)\n",
    "    for lr in lrs:\n",
    "        print(\"Learning rate: \", lr, 'Algo: ', algo)\n",
    "        accuracy, cost_train, cost_dev, accuracy_train, accuracy_dev = run_train_test(algo, all_data, all_labels, backward_prop, num_epochs, plot, learning_rate=lr)\n",
    "        algo_dict['Test Accuracy'].append(accuracy)\n",
    "        algo_dict['Train Accuracy'].append(accuracy_train)\n",
    "        algo_dict['Dev Accuracy'].append(accuracy_dev)\n",
    "        algo_dict['Dev Loss'].append(cost_dev)\n",
    "        algo_dict['Train Loss'].append(cost_train)\n",
    "        results[algo] = algo_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LMS': defaultdict(list,\n",
       "             {'Test Accuracy': [0.8707,\n",
       "               0.9093,\n",
       "               0.9177,\n",
       "               0.9426,\n",
       "               0.9591,\n",
       "               0.952,\n",
       "               0.9434,\n",
       "               0.9249,\n",
       "               0.894,\n",
       "               0.8588,\n",
       "               0.8838,\n",
       "               0.883,\n",
       "               0.8394,\n",
       "               0.8451],\n",
       "              'Train Accuracy': [0.8974,\n",
       "               0.95442,\n",
       "               0.97084,\n",
       "               0.99362,\n",
       "               0.9856,\n",
       "               0.9683,\n",
       "               0.95956,\n",
       "               0.93352,\n",
       "               0.90074,\n",
       "               0.86634,\n",
       "               0.893,\n",
       "               0.87814,\n",
       "               0.8408,\n",
       "               0.8392],\n",
       "              'Dev Accuracy': [0.8676,\n",
       "               0.9048,\n",
       "               0.9156,\n",
       "               0.9431,\n",
       "               0.9589,\n",
       "               0.9528,\n",
       "               0.9457,\n",
       "               0.9205,\n",
       "               0.8974,\n",
       "               0.8615,\n",
       "               0.8841,\n",
       "               0.8809,\n",
       "               0.8387,\n",
       "               0.8422],\n",
       "              'Dev Loss': [0.5117597136446393,\n",
       "               0.3455427191046529,\n",
       "               0.30772276600564813,\n",
       "               0.2670775659610023,\n",
       "               0.1998553311722382,\n",
       "               0.1873679028596692,\n",
       "               0.21741051392845107,\n",
       "               0.36945631781783317,\n",
       "               0.892295616460129,\n",
       "               2.1396811171088252,\n",
       "               0.6762072323150012,\n",
       "               2.380059417805161,\n",
       "               2.938954556140084,\n",
       "               3.469173558033381],\n",
       "              'Train Loss': [0.3735457624101224,\n",
       "               0.16131087229983285,\n",
       "               0.10444757910089063,\n",
       "               0.02480208343787856,\n",
       "               0.043626351184616524,\n",
       "               0.10431157767675411,\n",
       "               0.15384279754611846,\n",
       "               0.28315283721095597,\n",
       "               0.8309708225809931,\n",
       "               2.0496611275076804,\n",
       "               0.5943194650742338,\n",
       "               2.3577307466281825,\n",
       "               2.946791107722773,\n",
       "               3.507336056973992]}),\n",
       " '%LMS': defaultdict(list,\n",
       "             {'Test Accuracy': [0.8555,\n",
       "               0.8964,\n",
       "               0.9127,\n",
       "               0.9376,\n",
       "               0.9493,\n",
       "               0.9572,\n",
       "               0.9636,\n",
       "               0.9613,\n",
       "               0.958,\n",
       "               0.9501,\n",
       "               0.9451,\n",
       "               0.9208,\n",
       "               0.7869,\n",
       "               0.8778],\n",
       "              'Train Accuracy': [0.87784,\n",
       "               0.9419,\n",
       "               0.96064,\n",
       "               0.98598,\n",
       "               0.98786,\n",
       "               0.9803,\n",
       "               0.98052,\n",
       "               0.97586,\n",
       "               0.96746,\n",
       "               0.9593,\n",
       "               0.94712,\n",
       "               0.92502,\n",
       "               0.7878,\n",
       "               0.8794],\n",
       "              'Dev Accuracy': [0.8529,\n",
       "               0.8969,\n",
       "               0.9092,\n",
       "               0.9342,\n",
       "               0.9487,\n",
       "               0.955,\n",
       "               0.9608,\n",
       "               0.9618,\n",
       "               0.9562,\n",
       "               0.9493,\n",
       "               0.9399,\n",
       "               0.9165,\n",
       "               0.7862,\n",
       "               0.8808],\n",
       "              'Dev Loss': [0.5626445069450526,\n",
       "               0.3610258855268068,\n",
       "               0.3210873016179855,\n",
       "               0.27745620535127447,\n",
       "               0.2285764074349785,\n",
       "               0.1762217183536944,\n",
       "               0.14128693466236336,\n",
       "               0.1316675787099467,\n",
       "               0.15399062946979541,\n",
       "               0.17017821149468537,\n",
       "               0.21496641285411192,\n",
       "               0.300184387339191,\n",
       "               0.7484793940238763,\n",
       "               0.4392697097790558],\n",
       "              'Train Loss': [0.4413626275406849,\n",
       "               0.20425841481546078,\n",
       "               0.14365761623040843,\n",
       "               0.048335237672699725,\n",
       "               0.038979169007992163,\n",
       "               0.06186769637143362,\n",
       "               0.059618944402377194,\n",
       "               0.07922500942445322,\n",
       "               0.10837066449743575,\n",
       "               0.1334850084072496,\n",
       "               0.17952218480001614,\n",
       "               0.2643505545539981,\n",
       "               0.7325555441003375,\n",
       "               0.42238837542637475]})}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training loss and plot the accuracy as a function of learning rates\n",
    "fig, ax = plt.subplots()\n",
    "for algo in algos:\n",
    "    train_loss = results[algo]['Train Loss']\n",
    "    plt.semilogx(lrs, train_loss, 'x-', label=algo)\n",
    "plt.legend()\n",
    "plt.xlabel(r'Learning rate $\\alpha$')\n",
    "plt.ylabel('Training cross-entropy loss')\n",
    "plt.savefig('mnist_loss_lr.png', dpi=200)\n",
    "# ax.xaxis.set_major_formatter(ScalarFormatter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy as a function of learning rates\n",
    "for algo in algos:\n",
    "    train_loss = results[algo]['Test Accuracy']\n",
    "    plt.semilogx(lrs, train_loss, 'x-', label=algo)\n",
    "plt.legend()\n",
    "plt.xlabel(r'Learning rate $\\alpha$')\n",
    "plt.ylabel('Test accuracy')\n",
    "plt.savefig('mnist_acc_lr.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
